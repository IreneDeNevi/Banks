{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IreneDeNevi/Banks/blob/main/banks_project_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ECATE68fXTOq"
      },
      "source": [
        "# ETL Project: Top 10 Largest Banks by Market Capitalization\n",
        "\n",
        "## Project Overview\n",
        "This notebook extracts data about the top 10 largest banks in the world by market capitalization, transforms the data by converting USD to GBP, EUR, and INR, and loads the data to both CSV and SQLite database.\n",
        "\n",
        "## Setup Instructions\n",
        "1. Run all cells in order\n",
        "2. The script will automatically download the exchange rate CSV\n",
        "3. All outputs (CSV, database, log file) will be created in your Colab environment\n",
        "4. You can download the files from the Files panel on the left"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0j9wJnrXTOs"
      },
      "source": [
        "## Step 1: Install Required Libraries\n",
        "Most libraries are pre-installed in Colab, but let's ensure everything is available."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Ua2vOqrHXTOt"
      },
      "outputs": [],
      "source": [
        "# Install required libraries (if not already installed)\n",
        "!pip install beautifulsoup4 requests pandas numpy -q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCIXqjc8XTOu"
      },
      "source": [
        "## Step 2: Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EC4GFmEVXTOu",
        "outputId": "95ea6365-8db7-47db-c0b4-b029036351a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All libraries imported successfully!\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sqlite3\n",
        "from datetime import datetime\n",
        "\n",
        "print(\"All libraries imported successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLB0elSPXTOu"
      },
      "source": [
        "## Step 3: Define Configuration Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qD1ujpCPXTOu",
        "outputId": "ce2488c3-994c-4c92-ddb2-4cc18b4d0c81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Configuration complete!\n"
          ]
        }
      ],
      "source": [
        "# Configuration Parameters\n",
        "URL = 'https://web.archive.org/web/20230908091635/https://en.wikipedia.org/wiki/List_of_largest_banks'\n",
        "EXCHANGE_RATE_CSV = 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-PY0221EN-Coursera/labs/v2/exchange_rate.csv'\n",
        "OUTPUT_CSV_PATH = './Largest_banks_data.csv'\n",
        "DATABASE_NAME = 'Banks.db'\n",
        "TABLE_NAME = 'Largest_banks'\n",
        "LOG_FILE = 'code_log.txt'\n",
        "\n",
        "print(\"Configuration complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zc4lylAZXTOv"
      },
      "source": [
        "## Task 1: Logging Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XpsI4yjEXTOv",
        "outputId": "f8d4ee5a-5642-4da3-92d8-4dfd1f6d94e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-11-17 15:10:13 : Preliminaries complete. Initiating ETL process\n"
          ]
        }
      ],
      "source": [
        "def log_progress(message):\n",
        "    \"\"\"\n",
        "    Log the progress of the code execution with timestamp.\n",
        "\n",
        "    Parameters:\n",
        "    message (str): The log message to be written\n",
        "    \"\"\"\n",
        "    timestamp_format = '%Y-%m-%d %H:%M:%S'\n",
        "    now = datetime.now()\n",
        "    timestamp = now.strftime(timestamp_format)\n",
        "\n",
        "    with open(LOG_FILE, 'a') as f:\n",
        "        f.write(f'{timestamp} : {message}\\n')\n",
        "\n",
        "    print(f'{timestamp} : {message}')\n",
        "\n",
        "# Clear previous log file\n",
        "open(LOG_FILE, 'w').close()\n",
        "log_progress('Preliminaries complete. Initiating ETL process')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUUqsuhyXTOv"
      },
      "source": [
        "## Task 2: Extract Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8EdI7mmZXTOv",
        "outputId": "ab29496d-6ca0-4e1a-b54a-c1b242c49ca2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-11-17 15:10:13 : Data extraction started\n",
            "2025-11-17 15:10:14 : Data extraction complete. Initiating Transformation process\n",
            "\n",
            "Extracted Data:\n",
            "                                      Name  MC_USD_Billion\n",
            "0                           JPMorgan Chase          432.92\n",
            "1                          Bank of America          231.52\n",
            "2  Industrial and Commercial Bank of China          194.56\n",
            "3               Agricultural Bank of China          160.68\n",
            "4                                HDFC Bank          157.91\n",
            "5                              Wells Fargo          155.87\n",
            "6                        HSBC Holdings PLC          148.90\n",
            "7                           Morgan Stanley          140.83\n",
            "8                  China Construction Bank          139.82\n",
            "9                            Bank of China          136.81\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2084099673.py:53: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df = pd.concat([df, new_row], ignore_index=True)\n"
          ]
        }
      ],
      "source": [
        "def extract(url, table_attribs):\n",
        "    \"\"\"\n",
        "    Extract tabular data from the given URL.\n",
        "\n",
        "    Parameters:\n",
        "    url (str): The URL to extract data from\n",
        "    table_attribs (list): List of column names for the dataframe\n",
        "\n",
        "    Returns:\n",
        "    pd.DataFrame: Extracted data as a pandas DataFrame\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Fetch the webpage content\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()\n",
        "\n",
        "        # Parse HTML content\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "        # Find all tables in the page\n",
        "        tables = soup.find_all('table', {'class': 'wikitable'})\n",
        "\n",
        "        # Initialize empty dataframe\n",
        "        df = pd.DataFrame(columns=table_attribs)\n",
        "\n",
        "        # Find the correct table (by market capitalization)\n",
        "        if tables:\n",
        "            table = tables[0]\n",
        "            rows = table.find_all('tr')\n",
        "\n",
        "            # Extract data from rows (skip header)\n",
        "            for row in rows[1:]:\n",
        "                cols = row.find_all('td')\n",
        "                if len(cols) >= 3:  # Ensure row has enough columns\n",
        "                    # Extract bank name (second column)\n",
        "                    bank_name = cols[1].get_text(strip=True)\n",
        "\n",
        "                    # Extract market cap (third column)\n",
        "                    market_cap = cols[2].get_text(strip=True)\n",
        "\n",
        "                    # Clean market cap value\n",
        "                    market_cap = market_cap.replace(',', '').replace('\\n', '')\n",
        "\n",
        "                    # Try to convert to float\n",
        "                    try:\n",
        "                        market_cap_value = float(market_cap)\n",
        "\n",
        "                        # Add to dataframe\n",
        "                        new_row = pd.DataFrame({\n",
        "                            table_attribs[0]: [bank_name],\n",
        "                            table_attribs[1]: [market_cap_value]\n",
        "                        })\n",
        "                        df = pd.concat([df, new_row], ignore_index=True)\n",
        "\n",
        "                        # Stop after getting top 10 banks\n",
        "                        if len(df) >= 10:\n",
        "                            break\n",
        "                    except ValueError:\n",
        "                        continue\n",
        "\n",
        "        return df\n",
        "\n",
        "    except Exception as e:\n",
        "        log_progress(f'Error during extraction: {str(e)}')\n",
        "        return pd.DataFrame(columns=table_attribs)\n",
        "\n",
        "# Execute extraction\n",
        "log_progress('Data extraction started')\n",
        "extracted_data = extract(URL, ['Name', 'MC_USD_Billion'])\n",
        "log_progress('Data extraction complete. Initiating Transformation process')\n",
        "\n",
        "print(\"\\nExtracted Data:\")\n",
        "print(extracted_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BwOx_HvxXTOv"
      },
      "source": [
        "## Task 3: Transform Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_60FT04XTOv",
        "outputId": "61463554-ac96-4932-c224-3312037b098a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-11-17 15:10:14 : Data transformation started\n",
            "\n",
            "Exchange Rates:\n",
            "  Currency   Rate\n",
            "0      EUR   0.93\n",
            "1      GBP   0.80\n",
            "2      INR  82.95\n",
            "2025-11-17 15:10:15 : Data transformation complete. Initiating Loading process\n",
            "\n",
            "Transformed Data:\n",
            "                                      Name  MC_USD_Billion  MC_GBP_Billion  \\\n",
            "0                           JPMorgan Chase          432.92          346.34   \n",
            "1                          Bank of America          231.52          185.22   \n",
            "2  Industrial and Commercial Bank of China          194.56          155.65   \n",
            "3               Agricultural Bank of China          160.68          128.54   \n",
            "4                                HDFC Bank          157.91          126.33   \n",
            "5                              Wells Fargo          155.87          124.70   \n",
            "6                        HSBC Holdings PLC          148.90          119.12   \n",
            "7                           Morgan Stanley          140.83          112.66   \n",
            "8                  China Construction Bank          139.82          111.86   \n",
            "9                            Bank of China          136.81          109.45   \n",
            "\n",
            "   MC_EUR_Billion  MC_INR_Billion  \n",
            "0          402.62        35910.71  \n",
            "1          215.31        19204.58  \n",
            "2          180.94        16138.75  \n",
            "3          149.43        13328.41  \n",
            "4          146.86        13098.63  \n",
            "5          144.96        12929.42  \n",
            "6          138.48        12351.26  \n",
            "7          130.97        11681.85  \n",
            "8          130.03        11598.07  \n",
            "9          127.23        11348.39  \n"
          ]
        }
      ],
      "source": [
        "def transform(df, csv_path):\n",
        "    \"\"\"\n",
        "    Transform the dataframe by adding currency conversion columns.\n",
        "\n",
        "    Parameters:\n",
        "    df (pd.DataFrame): Input dataframe with bank data\n",
        "    csv_path (str): Path to the exchange rate CSV file\n",
        "\n",
        "    Returns:\n",
        "    pd.DataFrame: Transformed dataframe with additional currency columns\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Read exchange rate CSV\n",
        "        exchange_rates = pd.read_csv(csv_path)\n",
        "\n",
        "        print(\"\\nExchange Rates:\")\n",
        "        print(exchange_rates)\n",
        "\n",
        "        # Create a dictionary for easy lookup\n",
        "        exchange_dict = exchange_rates.set_index('Currency')['Rate'].to_dict()\n",
        "\n",
        "        # Add new columns with currency conversions\n",
        "        df['MC_GBP_Billion'] = [np.round(x * exchange_dict['GBP'], 2) for x in df['MC_USD_Billion']]\n",
        "        df['MC_EUR_Billion'] = [np.round(x * exchange_dict['EUR'], 2) for x in df['MC_USD_Billion']]\n",
        "        df['MC_INR_Billion'] = [np.round(x * exchange_dict['INR'], 2) for x in df['MC_USD_Billion']]\n",
        "\n",
        "        return df\n",
        "\n",
        "    except Exception as e:\n",
        "        log_progress(f'Error during transformation: {str(e)}')\n",
        "        return df\n",
        "\n",
        "# Execute transformation\n",
        "log_progress('Data transformation started')\n",
        "transformed_data = transform(extracted_data, EXCHANGE_RATE_CSV)\n",
        "log_progress('Data transformation complete. Initiating Loading process')\n",
        "\n",
        "print(\"\\nTransformed Data:\")\n",
        "print(transformed_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRCKJKHbXTOv"
      },
      "source": [
        "## Task 4: Load to CSV Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f81Pi4EpXTOv",
        "outputId": "d07f587a-62c6-4170-9ec8-56b19d3cb74e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-11-17 15:10:15 : Loading data to CSV\n",
            "2025-11-17 15:10:15 : Data saved to CSV file: ./Largest_banks_data.csv\n",
            "2025-11-17 15:10:15 : Data saved to CSV file\n",
            "\n",
            "Verifying CSV file:\n",
            "                                      Name  MC_USD_Billion  MC_GBP_Billion  \\\n",
            "0                           JPMorgan Chase          432.92          346.34   \n",
            "1                          Bank of America          231.52          185.22   \n",
            "2  Industrial and Commercial Bank of China          194.56          155.65   \n",
            "3               Agricultural Bank of China          160.68          128.54   \n",
            "4                                HDFC Bank          157.91          126.33   \n",
            "\n",
            "   MC_EUR_Billion  MC_INR_Billion  \n",
            "0          402.62        35910.71  \n",
            "1          215.31        19204.58  \n",
            "2          180.94        16138.75  \n",
            "3          149.43        13328.41  \n",
            "4          146.86        13098.63  \n"
          ]
        }
      ],
      "source": [
        "def load_to_csv(df, output_path):\n",
        "    \"\"\"\n",
        "    Load the dataframe to a CSV file.\n",
        "\n",
        "    Parameters:\n",
        "    df (pd.DataFrame): Dataframe to save\n",
        "    output_path (str): Path where CSV will be saved\n",
        "    \"\"\"\n",
        "    try:\n",
        "        df.to_csv(output_path, index=False)\n",
        "        log_progress(f'Data saved to CSV file: {output_path}')\n",
        "    except Exception as e:\n",
        "        log_progress(f'Error saving to CSV: {str(e)}')\n",
        "\n",
        "# Execute CSV loading\n",
        "log_progress('Loading data to CSV')\n",
        "load_to_csv(transformed_data, OUTPUT_CSV_PATH)\n",
        "log_progress('Data saved to CSV file')\n",
        "\n",
        "# Verify CSV was created\n",
        "print(\"\\nVerifying CSV file:\")\n",
        "csv_check = pd.read_csv(OUTPUT_CSV_PATH)\n",
        "print(csv_check.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tBuI9cHXTOv"
      },
      "source": [
        "## Task 5: Load to Database Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-R57fRSXTOw",
        "outputId": "aacb6c9a-f8fe-41a4-85f6-eacbcebc2372"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-11-17 15:10:15 : Initiating connection to SQLite database\n",
            "2025-11-17 15:10:15 : SQL Connection initiated\n",
            "2025-11-17 15:10:15 : Data loaded to database table: Largest_banks\n",
            "2025-11-17 15:10:15 : Data loaded to Database as a table, Executing queries\n"
          ]
        }
      ],
      "source": [
        "def load_to_db(df, sql_connection, table_name):\n",
        "    \"\"\"\n",
        "    Load the dataframe to an SQL database table.\n",
        "\n",
        "    Parameters:\n",
        "    df (pd.DataFrame): Dataframe to save\n",
        "    sql_connection: SQLite database connection\n",
        "    table_name (str): Name of the table to create/replace\n",
        "    \"\"\"\n",
        "    try:\n",
        "        df.to_sql(table_name, sql_connection, if_exists='replace', index=False)\n",
        "        log_progress(f'Data loaded to database table: {table_name}')\n",
        "    except Exception as e:\n",
        "        log_progress(f'Error loading to database: {str(e)}')\n",
        "\n",
        "# Execute database loading\n",
        "log_progress('Initiating connection to SQLite database')\n",
        "conn = sqlite3.connect(DATABASE_NAME)\n",
        "log_progress('SQL Connection initiated')\n",
        "\n",
        "load_to_db(transformed_data, conn, TABLE_NAME)\n",
        "log_progress('Data loaded to Database as a table, Executing queries')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BmrDIC2BXTOw"
      },
      "source": [
        "## Task 6: Run Database Queries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJRa1UeRXTOw",
        "outputId": "2c60dcd2-6438-4386-8040-9a9a4c87bc4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "Running Database Queries\n",
            "==================================================\n",
            "\n",
            "Query: SELECT * FROM Largest_banks\n",
            "                                      Name  MC_USD_Billion  MC_GBP_Billion  \\\n",
            "0                           JPMorgan Chase          432.92          346.34   \n",
            "1                          Bank of America          231.52          185.22   \n",
            "2  Industrial and Commercial Bank of China          194.56          155.65   \n",
            "3               Agricultural Bank of China          160.68          128.54   \n",
            "4                                HDFC Bank          157.91          126.33   \n",
            "5                              Wells Fargo          155.87          124.70   \n",
            "6                        HSBC Holdings PLC          148.90          119.12   \n",
            "7                           Morgan Stanley          140.83          112.66   \n",
            "8                  China Construction Bank          139.82          111.86   \n",
            "9                            Bank of China          136.81          109.45   \n",
            "\n",
            "   MC_EUR_Billion  MC_INR_Billion  \n",
            "0          402.62        35910.71  \n",
            "1          215.31        19204.58  \n",
            "2          180.94        16138.75  \n",
            "3          149.43        13328.41  \n",
            "4          146.86        13098.63  \n",
            "5          144.96        12929.42  \n",
            "6          138.48        12351.26  \n",
            "7          130.97        11681.85  \n",
            "8          130.03        11598.07  \n",
            "9          127.23        11348.39  \n",
            "2025-11-17 15:10:15 : Query executed: SELECT * FROM Largest_banks\n",
            "\n",
            "Query: SELECT AVG(MC_GBP_Billion) AS Average_MC_GBP FROM Largest_banks\n",
            "   Average_MC_GBP\n",
            "0         151.987\n",
            "2025-11-17 15:10:15 : Query executed: SELECT AVG(MC_GBP_Billion) AS Average_MC_GBP FROM Largest_banks\n",
            "\n",
            "Query: SELECT Name FROM Largest_banks LIMIT 5\n",
            "                                      Name\n",
            "0                           JPMorgan Chase\n",
            "1                          Bank of America\n",
            "2  Industrial and Commercial Bank of China\n",
            "3               Agricultural Bank of China\n",
            "4                                HDFC Bank\n",
            "2025-11-17 15:10:15 : Query executed: SELECT Name FROM Largest_banks LIMIT 5\n",
            "2025-11-17 15:10:15 : Process Complete\n",
            "2025-11-17 15:10:15 : Server Connection closed\n"
          ]
        }
      ],
      "source": [
        "def run_query(query, sql_connection):\n",
        "    \"\"\"\n",
        "    Run a query on the database and print results.\n",
        "\n",
        "    Parameters:\n",
        "    query (str): SQL query to execute\n",
        "    sql_connection: SQLite database connection\n",
        "    \"\"\"\n",
        "    try:\n",
        "        print(f\"\\nQuery: {query}\")\n",
        "        result = pd.read_sql_query(query, sql_connection)\n",
        "        print(result)\n",
        "        log_progress(f'Query executed: {query}')\n",
        "    except Exception as e:\n",
        "        log_progress(f'Error running query: {str(e)}')\n",
        "        print(f\"Error: {e}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Running Database Queries\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Query 1: Print all contents of the table\n",
        "query1 = f\"SELECT * FROM {TABLE_NAME}\"\n",
        "run_query(query1, conn)\n",
        "\n",
        "# Query 2: Print average market capitalization in GBP\n",
        "query2 = f\"SELECT AVG(MC_GBP_Billion) AS Average_MC_GBP FROM {TABLE_NAME}\"\n",
        "run_query(query2, conn)\n",
        "\n",
        "# Query 3: Print only the names of top 5 banks\n",
        "query3 = f\"SELECT Name FROM {TABLE_NAME} LIMIT 5\"\n",
        "run_query(query3, conn)\n",
        "\n",
        "log_progress('Process Complete')\n",
        "\n",
        "# Close database connection\n",
        "conn.close()\n",
        "log_progress('Server Connection closed')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fBvtnIQgXTOw"
      },
      "source": [
        "## Task 7: Verify Log Entries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6Wl58nbXTOw",
        "outputId": "039aabed-67bb-4a0e-f300-54ae06db1c28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "Log File Contents\n",
            "==================================================\n",
            "2025-11-17 15:10:13 : Preliminaries complete. Initiating ETL process\n",
            "2025-11-17 15:10:13 : Data extraction started\n",
            "2025-11-17 15:10:14 : Data extraction complete. Initiating Transformation process\n",
            "2025-11-17 15:10:14 : Data transformation started\n",
            "2025-11-17 15:10:15 : Data transformation complete. Initiating Loading process\n",
            "2025-11-17 15:10:15 : Loading data to CSV\n",
            "2025-11-17 15:10:15 : Data saved to CSV file: ./Largest_banks_data.csv\n",
            "2025-11-17 15:10:15 : Data saved to CSV file\n",
            "2025-11-17 15:10:15 : Initiating connection to SQLite database\n",
            "2025-11-17 15:10:15 : SQL Connection initiated\n",
            "2025-11-17 15:10:15 : Data loaded to database table: Largest_banks\n",
            "2025-11-17 15:10:15 : Data loaded to Database as a table, Executing queries\n",
            "2025-11-17 15:10:15 : Query executed: SELECT * FROM Largest_banks\n",
            "2025-11-17 15:10:15 : Query executed: SELECT AVG(MC_GBP_Billion) AS Average_MC_GBP FROM Largest_banks\n",
            "2025-11-17 15:10:15 : Query executed: SELECT Name FROM Largest_banks LIMIT 5\n",
            "2025-11-17 15:10:15 : Process Complete\n",
            "2025-11-17 15:10:15 : Server Connection closed\n",
            "\n",
            "\n",
            "==================================================\n",
            "ETL Process Completed Successfully!\n",
            "==================================================\n",
            "\n",
            "Generated Files:\n",
            "1. CSV File: ./Largest_banks_data.csv\n",
            "2. Database: Banks.db\n",
            "3. Log File: code_log.txt\n",
            "\n",
            "You can download these files from the Files panel on the left.\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Log File Contents\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "with open(LOG_FILE, 'r') as f:\n",
        "    log_contents = f.read()\n",
        "    print(log_contents)\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"ETL Process Completed Successfully!\")\n",
        "print(\"=\"*50)\n",
        "print(\"\\nGenerated Files:\")\n",
        "print(f\"1. CSV File: {OUTPUT_CSV_PATH}\")\n",
        "print(f\"2. Database: {DATABASE_NAME}\")\n",
        "print(f\"3. Log File: {LOG_FILE}\")\n",
        "print(\"\\nYou can download these files from the Files panel on the left.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCSeLZYtXTOw"
      },
      "source": [
        "## Download Files (Optional)\n",
        "Run this cell to download all generated files to your local machine."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "hTRys2-lXTOw",
        "outputId": "436f78f7-5c39-4f9d-be3d-6f9651ccde2d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_ee8fa2f7-9f89-43dc-9412-3aabe30b5105\", \"Largest_banks_data.csv\", 554)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_65c8e341-52f2-46c5-8697-c86bc2f4e10c\", \"Banks.db\", 8192)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_19a19bc0-c085-43ae-8f67-edf6e5de36a4\", \"code_log.txt\", 1068)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All files downloaded!\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Download CSV file\n",
        "files.download(OUTPUT_CSV_PATH)\n",
        "\n",
        "# Download database file\n",
        "files.download(DATABASE_NAME)\n",
        "\n",
        "# Download log file\n",
        "files.download(LOG_FILE)\n",
        "\n",
        "print(\"All files downloaded!\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}